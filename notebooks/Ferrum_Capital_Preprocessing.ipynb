{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpHFHhLpIJ3CYjSy3pLUik",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bahramzada/ferrum-capital-task-1/blob/main/notebooks/Ferrum_Capital_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Giriş\n",
        "\n",
        "Bu notebook-da model qurulmasından əvvəl dataset üzərində text preprocessing əməliyyatları həyata keçirilmişdir. Məqsəd mətnləri daha təmiz və standart formaya salmaqdır."
      ],
      "metadata": {
        "id": "QI3SDZ0Qckbr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6Sr7s3NGo1m",
        "outputId": "b239a887-faf4-4660-f9fe-460057478477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-28 11:53:58--  https://raw.githubusercontent.com/bahramzada/ferrum-capital-task-1/refs/heads/main/data/test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 201183 (196K) [text/plain]\n",
            "Saving to: ‘test.csv’\n",
            "\n",
            "\rtest.csv              0%[                    ]       0  --.-KB/s               \rtest.csv            100%[===================>] 196.47K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2026-01-28 11:53:58 (7.76 MB/s) - ‘test.csv’ saved [201183/201183]\n",
            "\n",
            "--2026-01-28 11:53:58--  https://raw.githubusercontent.com/bahramzada/ferrum-capital-task-1/refs/heads/main/data/training.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1613543 (1.5M) [text/plain]\n",
            "Saving to: ‘training.csv’\n",
            "\n",
            "training.csv        100%[===================>]   1.54M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2026-01-28 11:53:58 (25.7 MB/s) - ‘training.csv’ saved [1613543/1613543]\n",
            "\n",
            "--2026-01-28 11:53:58--  https://raw.githubusercontent.com/bahramzada/ferrum-capital-task-1/refs/heads/main/data/validation.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 198705 (194K) [text/plain]\n",
            "Saving to: ‘validation.csv’\n",
            "\n",
            "validation.csv      100%[===================>] 194.05K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2026-01-28 11:53:58 (5.88 MB/s) - ‘validation.csv’ saved [198705/198705]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/bahramzada/ferrum-capital-task-1/refs/heads/main/data/test.csv\n",
        "!wget https://raw.githubusercontent.com/bahramzada/ferrum-capital-task-1/refs/heads/main/data/training.csv\n",
        "!wget https://raw.githubusercontent.com/bahramzada/ferrum-capital-task-1/refs/heads/main/data/validation.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re"
      ],
      "metadata": {
        "id": "kWrhRUWsG4Cn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"training.csv\")\n",
        "val_df = pd.read_csv(\"validation.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")"
      ],
      "metadata": {
        "id": "AFNsi5muGwxl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_negation(text):\n",
        "    text = text.replace(\"didn't \", \"did_not_\")\n",
        "    text = text.replace(\"don't \", \"do_not_\")\n",
        "    text = text.replace(\"can't \", \"can_not_\")\n",
        "    text = text.replace(\"won't \", \"will_not_\")\n",
        "    text = text.replace(\"isn't \", \"is_not_\")\n",
        "    text = text.replace(\"aren't \", \"are_not_\")\n",
        "    text = text.replace(\"wasn't \", \"was_not_\")\n",
        "    text = text.replace(\"weren't \", \"were_not_\")\n",
        "    text = text.replace(\"not \", \"not_\")\n",
        "    return text"
      ],
      "metadata": {
        "id": "ARVTezJNZvpL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text preprocessing mərhələsi\n",
        "\n",
        "Bu mərhələdə mətnlər üzərində lowercase çevrilməsi, rəqəmlərin və punktuasiyanın silinməsi kimi əməliyyatlar tətbiq edilmişdir.Həmçinin negation strukturlarının emosional mənaya təsiri nəzərə alınaraq preprocessing prosesinə negation-aware yanaşma əlavə edilmişdir."
      ],
      "metadata": {
        "id": "zcnk83oxcqky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = handle_negation(text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "DdHFqpfXG9vf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['clean_text'] = train_df['text'].apply(clean_text)\n",
        "val_df['clean_text'] = val_df['text'].apply(clean_text)\n",
        "test_df['clean_text'] = test_df['text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "W_od3mgbHBJK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv(\"train_clean.csv\", index=False)\n",
        "val_df.to_csv(\"val_clean.csv\", index=False)\n",
        "test_df.to_csv(\"test_clean.csv\", index=False)"
      ],
      "metadata": {
        "id": "TwzvtnK8HJ8k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing nəticələri\n",
        "\n",
        "Preprocessing mərhələsindən sonra əldə edilən təmizlənmiş dataset-lər növbəti mərhələdə model qurulması üçün ayrıca saxlanılmışdır.\n"
      ],
      "metadata": {
        "id": "WXUMmfe4c9xa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iKItEp6pdBAn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}